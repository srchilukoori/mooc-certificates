# École Polytechnique Fédérale de Lausanne

## Functional Programming in Scala Scecialization

Specialization: In progress

### Functional Programming Principles in Scala
#### 1 of 5 in Functional Programming in Scala Specialization

Functional programming is becoming increasingly widespread in industry. This trend is driven by the adoption of Scala as the main programming language for many applications. Scala fuses functional and object-oriented programming in a practical package. It interoperates seamlessly with both Java and Javascript. Scala is the implementation language of many important frameworks, including Apache Spark, Kafka, and Akka. It provides the core infrastructure for sites such as Twitter, Netflix, Zalando, and also Coursera.

In this course, you will discover the elements of the functional programming style and learn how to apply them usefully in your daily programming tasks, such as modeling business domains or implementing business logic. You will also develop a solid foundation for reasoning about functional programs, by touching upon proofs of invariants and the tracing of execution symbolically.

The course is hands-on; most units introduce short programs that serve as illustrations of important concepts and invite you to play with them, modifying and improving them. The course is complemented by a series of programming projects as homework assignments.

Recommended background: You should have at least one year of programming experience. Proficiency with Java or C# is ideal, but experience with other languages such as C/C++, Python, Javascript, or Ruby is also sufficient. You should have some background in mathematics (e.g., algebra, logic, proof by induction). Last, you should have some familiarity with using the command line.

Topics include:

- Higher Order Functions
- Data and Abstraction
- Types and Pattern Matching
- Lists
- Collections

Certification: [https://www.coursera.org/account/accomplishments/verify/T5RD4QSURJ5J](https://www.coursera.org/account/accomplishments/verify/T5RD4QSURJ5J)


### Functional Program Design in Scala
#### 2 of 5 in Functional Programming in Scala Specialization

In this course you will learn how to apply the functional programming style in the design of larger Scala applications. You'll get to know important new functional programming concepts, from lazy evaluation to structuring your libraries using monads. We'll work on larger and more involved examples, from state space exploration to random testing to discrete circuit simulators. You’ll also learn some best practices on how to write good Scala code in the real world. Finally, you will learn how to leverage the ability of the compiler to infer values from types.

Several parts of this course deal with the question how functional programming interacts with mutable state. We will explore the consequences of combining functions and state. We will also look at purely functional alternatives to mutable state, using infinite data structures or functional reactive programming.

Recommended background: You should have at least one year programming experience. Proficiency with Java or C# is ideal, but experience with other languages such as C/C++, Python, Javascript or Ruby is also sufficient. You should have some familiarity with using the command line. This course is intended to be taken after Functional Programming Principles in Scala: https://www.coursera.org/learn/progfun1.

Topics include:

- For Expression and Monads
- Lazy Evaluation
- Type Directed Programming
- Functions and State
- Timely Effects

Certification: [https://www.coursera.org/account/accomplishments/verify/KR3G3PQQ4CHV](https://www.coursera.org/account/accomplishments/verify/KR3G3PQQ4CHV)


# University of California, Davis

### Distributed Computing with Spark SQL
#### 3 of 5 in Functional Programming in Scala Specialization


This course is all about big data. It’s for students with SQL experience that want to take the next step on their data journey by learning distributed computing using Apache Spark. Students will gain a thorough understanding of this open-source standard for working with large datasets. Students will gain an understanding of the fundamentals of data analysis using SQL on Spark, setting the foundation for how to combine data with advanced analytics at scale and in production environments. The four modules build on one another and by the end of the course you will understand: the Spark architecture, queries within Spark, common ways to optimize Spark SQL, and how to build reliable data pipelines.

The first module introduces Spark and the Databricks environment including how Spark distributes computation and Spark SQL. Module 2 covers the core concepts of Spark such as storage vs. compute, caching, partitions, and troubleshooting performance issues via the Spark UI. It also covers new features in Apache Spark 3.x such as Adaptive Query Execution. The third module focuses on Engineering Data Pipelines including connecting to databases, schemas and data types, file formats, and writing reliable data. The final module covers data lakes, data warehouses, and lakehouses. Students build production grade data pipelines by combining Spark with the open-source project Delta Lake. By the end of this course, students will hone their SQL and distributed computing skills to become more adept at advanced analysis and to set the stage for transitioning to more advanced analytics as Data Scientists.

Topics include:

- Introduction to Spark
- Spark Core Concepts
- Engineering Data Pipelines
- Data Lakes, Warehouses and Lakehouses

Certification: [https://www.coursera.org/account/accomplishments/verify/Y34Q8M5EBDJ8](https://www.coursera.org/account/accomplishments/verify/Y34Q8M5EBDJ8)
